{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 00:28:18.530156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-10 00:28:18.530258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-10 00:28:18.565529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-10 00:28:18.591842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-10 00:28:29.055558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08697ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/das214/SmartPix/BetterDG\n"
     ]
    }
   ],
   "source": [
    "# os.chdir('SmartPix/data_generator')\n",
    "os.chdir('SmartPix/BetterDG')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05666e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codesign_catapult.ipynb       plotting\n",
      "docs\t\t\t      preselection_processor.py\n",
      "evaluate.py\t\t      requirements.txt\n",
      "from_weights.ipynb\t      site\n",
      "loss.py\t\t\t      test_run.py\n",
      "Merge_plan_lab.ipynb\t      train_model_Better_DG.ipynb\n",
      "mergeplan.py\t\t      train_model_new_example.ipynb\n",
      "mkdocs.yml\t\t      train_model_optimized_giuseppe.ipynb\n",
      "model_batchnorm\t\t      train_model_optimized.ipynb\n",
      "models.py\t\t      train_model.py\n",
      "OptimizedDataGeneratorNew.py  utils.py\n",
      "OptimizedDataGenerator.py     xysum_model.py\n",
      "OptimizedDataGenerator_v2.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import OptimizedDataGenerator_v2\n",
    "\n",
    "importlib.reload(OptimizedDataGenerator_v2)\n",
    "from OptimizedDataGenerator_v2 import OptimizedDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170239d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from dataprep import *\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mOptimizedDataGenerator_v2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizedDataGenerator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/SmartPix/BetterDG/OptimizedDataGenerator_v2.py:41\u001b[0m\n\u001b[1;32m     37\u001b[0m     quantizer \u001b[38;5;241m=\u001b[39m quantized_bits(bits, int_bits, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quantizer(data)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mOptimizedDataGenerator\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     43\u001b[0m             dataset_base_dir: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m             batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     66\u001b[0m             ):\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m() \n",
      "File \u001b[0;32m~/SmartPix/BetterDG/OptimizedDataGenerator_v2.py:431\u001b[0m, in \u001b[0;36mOptimizedDataGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    427\u001b[0m             plan[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;241m=\u001b[39m (sec_start \u001b[38;5;241m+\u001b[39m half, sec_start \u001b[38;5;241m+\u001b[39m comb_len)\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plan\n\u001b[1;32m    430\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_batch_metadata\u001b[39m(\u001b[38;5;28mcls\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m, file_offsets: np\u001b[38;5;241m.\u001b[39mndarray, tail_tol: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.75\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[43mDict\u001b[49m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    Builds optimized batch metadata using a pre-computed batch plan.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    This ensures that the final batch is not excessively small.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     batching_plan \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_build_batching_plan(file_offsets, batch_size, tail_tol)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "#from dataprep import *\n",
    "# from OptimizedDataGenerator_v2 import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94db45-10a3-4aa0-9885-cad5c6cc25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_dir = \"/depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/\"\n",
    "tfrecords_base_dir = os.path.join(dataset_base_dir, \"TFR_files\", \"2t\")\n",
    "\n",
    "dataset_base_dir = os.path.join(dataset_base_dir, \"parquets\")\n",
    "tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train\")\n",
    "tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val\")\n",
    "\n",
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 75\n",
    "val_file_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccba057-7aa7-4b85-95bd-8977c14cf7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_val is removed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving batches as TFRecords:   0%|          | 0/102 [00:00<?, ?it/s]2025-06-09 22:46:34.270612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3234 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB MIG 1g.5gb, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "Saving batches as TFRecords: 100%|██████████| 102/102 [00:27<00:00,  3.70it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved successfully ast /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_val/metadata.json\n",
      "Loading metadata from /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_val/metadata.json\n",
      "--- Validation generator 43.51006531715393 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 75/75 [00:46<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_train is removed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving batches as TFRecords: 100%|██████████| 306/306 [01:14<00:00,  4.10it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved successfully ast /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_train/metadata.json\n",
      "Loading metadata from /depot/cms/users/das214/datasets/dataset_2s/dataset_2s_50x12P5_parquets/TFR_files/2t/TFR_train/metadata.json\n",
      "--- Training generator 122.80521893501282 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_base_dir,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    # optimize_batch_size = True,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,13,21), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, \n",
    "    files_from_end=True,\n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_val,\n",
    "    use_time_stamps = [0,19],\n",
    "    max_workers = 2\n",
    ")\n",
    "\n",
    "print(\"--- Validation generator %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# training generator\n",
    "start_time = time.time()\n",
    "training_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_base_dir,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    # optimize_batch_size = True,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,13,21), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, # True \n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    use_time_stamps = [0,19],\n",
    "    max_workers = 2\n",
    ")\n",
    "print(\"--- Training generator %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb2dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.file_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking auto normalization factors:\n",
      "Training generator norm factor pos: 1.4030861830865065\n",
      "Training generator norm factor neg: 2.4879350274661034\n",
      "\n",
      "Checking auto scale factors:\n",
      "Training generator labels scale: [74.36465612 18.59104573  8.60158289  0.53649678]\n",
      "Training generator dataset mean: [5.02385156]\n",
      "Training generator dataset std: [6.11337844]\n",
      "Training generator dataset max: 1.9337638243125104\n",
      "Training generator dataset min: -2.8022317516663517\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking auto normalization factors:\")\n",
    "print(\"Training generator norm factor pos:\", training_generator.norm_factor_pos)\n",
    "print(\"Training generator norm factor neg:\", training_generator.norm_factor_neg)\n",
    "print()\n",
    "print(\"Checking auto scale factors:\")\n",
    "print(\"Training generator labels scale:\", training_generator.labels_scale)\n",
    "print(\"Training generator dataset mean:\", training_generator.dataset_mean)\n",
    "print(\"Training generator dataset std:\", training_generator.dataset_std)\n",
    "print(\"Training generator dataset max:\", training_generator.dataset_max)\n",
    "print(\"Training generator dataset min:\", training_generator.dataset_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077183f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batch_idx': 0,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 0, 'row_start': 0, 'row_end': 4999}]},\n",
       " {'batch_idx': 1,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 0, 'row_start': 5000, 'row_end': 9999}]},\n",
       " {'batch_idx': 2,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 0, 'row_start': 10000, 'row_end': 14999}]},\n",
       " {'batch_idx': 3,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 0, 'row_start': 15000, 'row_end': 19999}]},\n",
       " {'batch_idx': 4,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 0, 'row_start': 20000, 'row_end': 20373},\n",
       "   {'file_idx': 1, 'row_start': 0, 'row_end': 4625}]},\n",
       " {'batch_idx': 5,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 1, 'row_start': 4626, 'row_end': 9625}]},\n",
       " {'batch_idx': 6,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 1, 'row_start': 9626, 'row_end': 14625}]},\n",
       " {'batch_idx': 7,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 1, 'row_start': 14626, 'row_end': 19625}]},\n",
       " {'batch_idx': 8,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 1, 'row_start': 19626, 'row_end': 20373},\n",
       "   {'file_idx': 2, 'row_start': 0, 'row_end': 4251}]},\n",
       " {'batch_idx': 9,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 2, 'row_start': 4252, 'row_end': 9251}]},\n",
       " {'batch_idx': 10,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 2, 'row_start': 9252, 'row_end': 14251}]},\n",
       " {'batch_idx': 11,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 2, 'row_start': 14252, 'row_end': 19251}]},\n",
       " {'batch_idx': 12,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 2, 'row_start': 19252, 'row_end': 20373},\n",
       "   {'file_idx': 3, 'row_start': 0, 'row_end': 3877}]},\n",
       " {'batch_idx': 13,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 3, 'row_start': 3878, 'row_end': 8877}]},\n",
       " {'batch_idx': 14,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 3, 'row_start': 8878, 'row_end': 13877}]},\n",
       " {'batch_idx': 15,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 3, 'row_start': 13878, 'row_end': 18877}]},\n",
       " {'batch_idx': 16,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 3, 'row_start': 18878, 'row_end': 20373},\n",
       "   {'file_idx': 4, 'row_start': 0, 'row_end': 3503}]},\n",
       " {'batch_idx': 17,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 4, 'row_start': 3504, 'row_end': 8503}]},\n",
       " {'batch_idx': 18,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 4, 'row_start': 8504, 'row_end': 13503}]},\n",
       " {'batch_idx': 19,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 4, 'row_start': 13504, 'row_end': 18503}]},\n",
       " {'batch_idx': 20,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 4, 'row_start': 18504, 'row_end': 20373},\n",
       "   {'file_idx': 5, 'row_start': 0, 'row_end': 3129}]},\n",
       " {'batch_idx': 21,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 5, 'row_start': 3130, 'row_end': 8129}]},\n",
       " {'batch_idx': 22,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 5, 'row_start': 8130, 'row_end': 13129}]},\n",
       " {'batch_idx': 23,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 5, 'row_start': 13130, 'row_end': 18129}]},\n",
       " {'batch_idx': 24,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 5, 'row_start': 18130, 'row_end': 20373},\n",
       "   {'file_idx': 6, 'row_start': 0, 'row_end': 2755}]},\n",
       " {'batch_idx': 25,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 6, 'row_start': 2756, 'row_end': 7755}]},\n",
       " {'batch_idx': 26,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 6, 'row_start': 7756, 'row_end': 12755}]},\n",
       " {'batch_idx': 27,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 6, 'row_start': 12756, 'row_end': 17755}]},\n",
       " {'batch_idx': 28,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 6, 'row_start': 17756, 'row_end': 20373},\n",
       "   {'file_idx': 7, 'row_start': 0, 'row_end': 2381}]},\n",
       " {'batch_idx': 29,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 7, 'row_start': 2382, 'row_end': 7381}]},\n",
       " {'batch_idx': 30,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 7, 'row_start': 7382, 'row_end': 12381}]},\n",
       " {'batch_idx': 31,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 7, 'row_start': 12382, 'row_end': 17381}]},\n",
       " {'batch_idx': 32,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 7, 'row_start': 17382, 'row_end': 20373},\n",
       "   {'file_idx': 8, 'row_start': 0, 'row_end': 2007}]},\n",
       " {'batch_idx': 33,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 8, 'row_start': 2008, 'row_end': 7007}]},\n",
       " {'batch_idx': 34,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 8, 'row_start': 7008, 'row_end': 12007}]},\n",
       " {'batch_idx': 35,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 8, 'row_start': 12008, 'row_end': 17007}]},\n",
       " {'batch_idx': 36,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 8, 'row_start': 17008, 'row_end': 20373},\n",
       "   {'file_idx': 9, 'row_start': 0, 'row_end': 1633}]},\n",
       " {'batch_idx': 37,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 9, 'row_start': 1634, 'row_end': 6633}]},\n",
       " {'batch_idx': 38,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 9, 'row_start': 6634, 'row_end': 11633}]},\n",
       " {'batch_idx': 39,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 9, 'row_start': 11634, 'row_end': 16633}]},\n",
       " {'batch_idx': 40,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 9, 'row_start': 16634, 'row_end': 20373},\n",
       "   {'file_idx': 10, 'row_start': 0, 'row_end': 1259}]},\n",
       " {'batch_idx': 41,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 10, 'row_start': 1260, 'row_end': 6259}]},\n",
       " {'batch_idx': 42,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 10, 'row_start': 6260, 'row_end': 11259}]},\n",
       " {'batch_idx': 43,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 10, 'row_start': 11260, 'row_end': 16259}]},\n",
       " {'batch_idx': 44,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 10, 'row_start': 16260, 'row_end': 20373},\n",
       "   {'file_idx': 11, 'row_start': 0, 'row_end': 885}]},\n",
       " {'batch_idx': 45,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 11, 'row_start': 886, 'row_end': 5885}]},\n",
       " {'batch_idx': 46,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 11, 'row_start': 5886, 'row_end': 10885}]},\n",
       " {'batch_idx': 47,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 11, 'row_start': 10886, 'row_end': 15885}]},\n",
       " {'batch_idx': 48,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 11, 'row_start': 15886, 'row_end': 20373},\n",
       "   {'file_idx': 12, 'row_start': 0, 'row_end': 511}]},\n",
       " {'batch_idx': 49,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 12, 'row_start': 512, 'row_end': 5511}]},\n",
       " {'batch_idx': 50,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 12, 'row_start': 5512, 'row_end': 10511}]},\n",
       " {'batch_idx': 51,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 12, 'row_start': 10512, 'row_end': 15511}]},\n",
       " {'batch_idx': 52,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 12, 'row_start': 15512, 'row_end': 20373},\n",
       "   {'file_idx': 13, 'row_start': 0, 'row_end': 137}]},\n",
       " {'batch_idx': 53,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 13, 'row_start': 138, 'row_end': 5137}]},\n",
       " {'batch_idx': 54,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 13, 'row_start': 5138, 'row_end': 10137}]},\n",
       " {'batch_idx': 55,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 13, 'row_start': 10138, 'row_end': 15137}]},\n",
       " {'batch_idx': 56,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 13, 'row_start': 15138, 'row_end': 20137}]},\n",
       " {'batch_idx': 57,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 13, 'row_start': 20138, 'row_end': 20373},\n",
       "   {'file_idx': 14, 'row_start': 0, 'row_end': 4763}]},\n",
       " {'batch_idx': 58,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 14, 'row_start': 4764, 'row_end': 9763}]},\n",
       " {'batch_idx': 59,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 14, 'row_start': 9764, 'row_end': 14763}]},\n",
       " {'batch_idx': 60,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 14, 'row_start': 14764, 'row_end': 19763}]},\n",
       " {'batch_idx': 61,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 14, 'row_start': 19764, 'row_end': 20373},\n",
       "   {'file_idx': 15, 'row_start': 0, 'row_end': 4389}]},\n",
       " {'batch_idx': 62,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 15, 'row_start': 4390, 'row_end': 9389}]},\n",
       " {'batch_idx': 63,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 15, 'row_start': 9390, 'row_end': 14389}]},\n",
       " {'batch_idx': 64,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 15, 'row_start': 14390, 'row_end': 19389}]},\n",
       " {'batch_idx': 65,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 15, 'row_start': 19390, 'row_end': 20373},\n",
       "   {'file_idx': 16, 'row_start': 0, 'row_end': 4015}]},\n",
       " {'batch_idx': 66,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 16, 'row_start': 4016, 'row_end': 9015}]},\n",
       " {'batch_idx': 67,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 16, 'row_start': 9016, 'row_end': 14015}]},\n",
       " {'batch_idx': 68,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 16, 'row_start': 14016, 'row_end': 19015}]},\n",
       " {'batch_idx': 69,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 16, 'row_start': 19016, 'row_end': 20373},\n",
       "   {'file_idx': 17, 'row_start': 0, 'row_end': 3641}]},\n",
       " {'batch_idx': 70,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 17, 'row_start': 3642, 'row_end': 8641}]},\n",
       " {'batch_idx': 71,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 17, 'row_start': 8642, 'row_end': 13641}]},\n",
       " {'batch_idx': 72,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 17, 'row_start': 13642, 'row_end': 18641}]},\n",
       " {'batch_idx': 73,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 17, 'row_start': 18642, 'row_end': 20373},\n",
       "   {'file_idx': 18, 'row_start': 0, 'row_end': 3267}]},\n",
       " {'batch_idx': 74,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 18, 'row_start': 3268, 'row_end': 8267}]},\n",
       " {'batch_idx': 75,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 18, 'row_start': 8268, 'row_end': 13267}]},\n",
       " {'batch_idx': 76,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 18, 'row_start': 13268, 'row_end': 18267}]},\n",
       " {'batch_idx': 77,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 18, 'row_start': 18268, 'row_end': 20373},\n",
       "   {'file_idx': 19, 'row_start': 0, 'row_end': 2893}]},\n",
       " {'batch_idx': 78,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 19, 'row_start': 2894, 'row_end': 7893}]},\n",
       " {'batch_idx': 79,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 19, 'row_start': 7894, 'row_end': 12893}]},\n",
       " {'batch_idx': 80,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 19, 'row_start': 12894, 'row_end': 17893}]},\n",
       " {'batch_idx': 81,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 19, 'row_start': 17894, 'row_end': 20373},\n",
       "   {'file_idx': 20, 'row_start': 0, 'row_end': 2519}]},\n",
       " {'batch_idx': 82,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 20, 'row_start': 2520, 'row_end': 7519}]},\n",
       " {'batch_idx': 83,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 20, 'row_start': 7520, 'row_end': 12519}]},\n",
       " {'batch_idx': 84,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 20, 'row_start': 12520, 'row_end': 17519}]},\n",
       " {'batch_idx': 85,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 20, 'row_start': 17520, 'row_end': 20373},\n",
       "   {'file_idx': 21, 'row_start': 0, 'row_end': 2145}]},\n",
       " {'batch_idx': 86,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 21, 'row_start': 2146, 'row_end': 7145}]},\n",
       " {'batch_idx': 87,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 21, 'row_start': 7146, 'row_end': 12145}]},\n",
       " {'batch_idx': 88,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 21, 'row_start': 12146, 'row_end': 17145}]},\n",
       " {'batch_idx': 89,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 21, 'row_start': 17146, 'row_end': 20373},\n",
       "   {'file_idx': 22, 'row_start': 0, 'row_end': 1771}]},\n",
       " {'batch_idx': 90,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 22, 'row_start': 1772, 'row_end': 6771}]},\n",
       " {'batch_idx': 91,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 22, 'row_start': 6772, 'row_end': 11771}]},\n",
       " {'batch_idx': 92,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 22, 'row_start': 11772, 'row_end': 16771}]},\n",
       " {'batch_idx': 93,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 22, 'row_start': 16772, 'row_end': 20373},\n",
       "   {'file_idx': 23, 'row_start': 0, 'row_end': 1397}]},\n",
       " {'batch_idx': 94,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 23, 'row_start': 1398, 'row_end': 6397}]},\n",
       " {'batch_idx': 95,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 23, 'row_start': 6398, 'row_end': 11397}]},\n",
       " {'batch_idx': 96,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 23, 'row_start': 11398, 'row_end': 16397}]},\n",
       " {'batch_idx': 97,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 23, 'row_start': 16398, 'row_end': 20373},\n",
       "   {'file_idx': 24, 'row_start': 0, 'row_end': 1023}]},\n",
       " {'batch_idx': 98,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 24, 'row_start': 1024, 'row_end': 6023}]},\n",
       " {'batch_idx': 99,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 24, 'row_start': 6024, 'row_end': 11023}]},\n",
       " {'batch_idx': 100,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 24, 'row_start': 11024, 'row_end': 16023}]},\n",
       " {'batch_idx': 101,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 24, 'row_start': 16024, 'row_end': 20373},\n",
       "   {'file_idx': 25, 'row_start': 0, 'row_end': 649}]},\n",
       " {'batch_idx': 102,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 25, 'row_start': 650, 'row_end': 5649}]},\n",
       " {'batch_idx': 103,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 25, 'row_start': 5650, 'row_end': 10649}]},\n",
       " {'batch_idx': 104,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 25, 'row_start': 10650, 'row_end': 15649}]},\n",
       " {'batch_idx': 105,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 25, 'row_start': 15650, 'row_end': 20373},\n",
       "   {'file_idx': 26, 'row_start': 0, 'row_end': 275}]},\n",
       " {'batch_idx': 106,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 26, 'row_start': 276, 'row_end': 5275}]},\n",
       " {'batch_idx': 107,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 26, 'row_start': 5276, 'row_end': 10275}]},\n",
       " {'batch_idx': 108,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 26, 'row_start': 10276, 'row_end': 15275}]},\n",
       " {'batch_idx': 109,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 26, 'row_start': 15276, 'row_end': 20275}]},\n",
       " {'batch_idx': 110,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 26, 'row_start': 20276, 'row_end': 20373},\n",
       "   {'file_idx': 27, 'row_start': 0, 'row_end': 4901}]},\n",
       " {'batch_idx': 111,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 27, 'row_start': 4902, 'row_end': 9901}]},\n",
       " {'batch_idx': 112,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 27, 'row_start': 9902, 'row_end': 14901}]},\n",
       " {'batch_idx': 113,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 27, 'row_start': 14902, 'row_end': 19901}]},\n",
       " {'batch_idx': 114,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 27, 'row_start': 19902, 'row_end': 20373},\n",
       "   {'file_idx': 28, 'row_start': 0, 'row_end': 4527}]},\n",
       " {'batch_idx': 115,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 28, 'row_start': 4528, 'row_end': 9527}]},\n",
       " {'batch_idx': 116,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 28, 'row_start': 9528, 'row_end': 14527}]},\n",
       " {'batch_idx': 117,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 28, 'row_start': 14528, 'row_end': 19527}]},\n",
       " {'batch_idx': 118,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 28, 'row_start': 19528, 'row_end': 20373},\n",
       "   {'file_idx': 29, 'row_start': 0, 'row_end': 4153}]},\n",
       " {'batch_idx': 119,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 29, 'row_start': 4154, 'row_end': 9153}]},\n",
       " {'batch_idx': 120,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 29, 'row_start': 9154, 'row_end': 14153}]},\n",
       " {'batch_idx': 121,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 29, 'row_start': 14154, 'row_end': 19153}]},\n",
       " {'batch_idx': 122,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 29, 'row_start': 19154, 'row_end': 20373},\n",
       "   {'file_idx': 30, 'row_start': 0, 'row_end': 3779}]},\n",
       " {'batch_idx': 123,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 30, 'row_start': 3780, 'row_end': 8779}]},\n",
       " {'batch_idx': 124,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 30, 'row_start': 8780, 'row_end': 13779}]},\n",
       " {'batch_idx': 125,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 30, 'row_start': 13780, 'row_end': 18779}]},\n",
       " {'batch_idx': 126,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 30, 'row_start': 18780, 'row_end': 20373},\n",
       "   {'file_idx': 31, 'row_start': 0, 'row_end': 3405}]},\n",
       " {'batch_idx': 127,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 31, 'row_start': 3406, 'row_end': 8405}]},\n",
       " {'batch_idx': 128,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 31, 'row_start': 8406, 'row_end': 13405}]},\n",
       " {'batch_idx': 129,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 31, 'row_start': 13406, 'row_end': 18405}]},\n",
       " {'batch_idx': 130,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 31, 'row_start': 18406, 'row_end': 20373},\n",
       "   {'file_idx': 32, 'row_start': 0, 'row_end': 3031}]},\n",
       " {'batch_idx': 131,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 32, 'row_start': 3032, 'row_end': 8031}]},\n",
       " {'batch_idx': 132,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 32, 'row_start': 8032, 'row_end': 13031}]},\n",
       " {'batch_idx': 133,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 32, 'row_start': 13032, 'row_end': 18031}]},\n",
       " {'batch_idx': 134,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 32, 'row_start': 18032, 'row_end': 20373},\n",
       "   {'file_idx': 33, 'row_start': 0, 'row_end': 2657}]},\n",
       " {'batch_idx': 135,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 33, 'row_start': 2658, 'row_end': 7657}]},\n",
       " {'batch_idx': 136,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 33, 'row_start': 7658, 'row_end': 12657}]},\n",
       " {'batch_idx': 137,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 33, 'row_start': 12658, 'row_end': 17657}]},\n",
       " {'batch_idx': 138,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 33, 'row_start': 17658, 'row_end': 20373},\n",
       "   {'file_idx': 34, 'row_start': 0, 'row_end': 2283}]},\n",
       " {'batch_idx': 139,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 34, 'row_start': 2284, 'row_end': 7283}]},\n",
       " {'batch_idx': 140,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 34, 'row_start': 7284, 'row_end': 12283}]},\n",
       " {'batch_idx': 141,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 34, 'row_start': 12284, 'row_end': 17283}]},\n",
       " {'batch_idx': 142,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 34, 'row_start': 17284, 'row_end': 20373},\n",
       "   {'file_idx': 35, 'row_start': 0, 'row_end': 1909}]},\n",
       " {'batch_idx': 143,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 35, 'row_start': 1910, 'row_end': 6909}]},\n",
       " {'batch_idx': 144,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 35, 'row_start': 6910, 'row_end': 11909}]},\n",
       " {'batch_idx': 145,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 35, 'row_start': 11910, 'row_end': 16909}]},\n",
       " {'batch_idx': 146,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 35, 'row_start': 16910, 'row_end': 20373},\n",
       "   {'file_idx': 36, 'row_start': 0, 'row_end': 1535}]},\n",
       " {'batch_idx': 147,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 36, 'row_start': 1536, 'row_end': 6535}]},\n",
       " {'batch_idx': 148,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 36, 'row_start': 6536, 'row_end': 11535}]},\n",
       " {'batch_idx': 149,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 36, 'row_start': 11536, 'row_end': 16535}]},\n",
       " {'batch_idx': 150,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 36, 'row_start': 16536, 'row_end': 20373},\n",
       "   {'file_idx': 37, 'row_start': 0, 'row_end': 1161}]},\n",
       " {'batch_idx': 151,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 37, 'row_start': 1162, 'row_end': 6161}]},\n",
       " {'batch_idx': 152,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 37, 'row_start': 6162, 'row_end': 11161}]},\n",
       " {'batch_idx': 153,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 37, 'row_start': 11162, 'row_end': 16161}]},\n",
       " {'batch_idx': 154,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 37, 'row_start': 16162, 'row_end': 20373},\n",
       "   {'file_idx': 38, 'row_start': 0, 'row_end': 787}]},\n",
       " {'batch_idx': 155,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 38, 'row_start': 788, 'row_end': 5787}]},\n",
       " {'batch_idx': 156,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 38, 'row_start': 5788, 'row_end': 10787}]},\n",
       " {'batch_idx': 157,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 38, 'row_start': 10788, 'row_end': 15787}]},\n",
       " {'batch_idx': 158,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 38, 'row_start': 15788, 'row_end': 20373},\n",
       "   {'file_idx': 39, 'row_start': 0, 'row_end': 413}]},\n",
       " {'batch_idx': 159,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 39, 'row_start': 414, 'row_end': 5413}]},\n",
       " {'batch_idx': 160,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 39, 'row_start': 5414, 'row_end': 10413}]},\n",
       " {'batch_idx': 161,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 39, 'row_start': 10414, 'row_end': 15413}]},\n",
       " {'batch_idx': 162,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 39, 'row_start': 15414, 'row_end': 20373},\n",
       "   {'file_idx': 40, 'row_start': 0, 'row_end': 39}]},\n",
       " {'batch_idx': 163,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 40, 'row_start': 40, 'row_end': 5039}]},\n",
       " {'batch_idx': 164,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 40, 'row_start': 5040, 'row_end': 10039}]},\n",
       " {'batch_idx': 165,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 40, 'row_start': 10040, 'row_end': 15039}]},\n",
       " {'batch_idx': 166,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 40, 'row_start': 15040, 'row_end': 20039}]},\n",
       " {'batch_idx': 167,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 40, 'row_start': 20040, 'row_end': 20373},\n",
       "   {'file_idx': 41, 'row_start': 0, 'row_end': 4665}]},\n",
       " {'batch_idx': 168,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 41, 'row_start': 4666, 'row_end': 9665}]},\n",
       " {'batch_idx': 169,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 41, 'row_start': 9666, 'row_end': 14665}]},\n",
       " {'batch_idx': 170,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 41, 'row_start': 14666, 'row_end': 19665}]},\n",
       " {'batch_idx': 171,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 41, 'row_start': 19666, 'row_end': 20373},\n",
       "   {'file_idx': 42, 'row_start': 0, 'row_end': 4291}]},\n",
       " {'batch_idx': 172,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 42, 'row_start': 4292, 'row_end': 9291}]},\n",
       " {'batch_idx': 173,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 42, 'row_start': 9292, 'row_end': 14291}]},\n",
       " {'batch_idx': 174,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 42, 'row_start': 14292, 'row_end': 19291}]},\n",
       " {'batch_idx': 175,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 42, 'row_start': 19292, 'row_end': 20373},\n",
       "   {'file_idx': 43, 'row_start': 0, 'row_end': 3917}]},\n",
       " {'batch_idx': 176,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 43, 'row_start': 3918, 'row_end': 8917}]},\n",
       " {'batch_idx': 177,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 43, 'row_start': 8918, 'row_end': 13917}]},\n",
       " {'batch_idx': 178,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 43, 'row_start': 13918, 'row_end': 18917}]},\n",
       " {'batch_idx': 179,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 43, 'row_start': 18918, 'row_end': 20373},\n",
       "   {'file_idx': 44, 'row_start': 0, 'row_end': 3543}]},\n",
       " {'batch_idx': 180,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 44, 'row_start': 3544, 'row_end': 8543}]},\n",
       " {'batch_idx': 181,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 44, 'row_start': 8544, 'row_end': 13543}]},\n",
       " {'batch_idx': 182,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 44, 'row_start': 13544, 'row_end': 18543}]},\n",
       " {'batch_idx': 183,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 44, 'row_start': 18544, 'row_end': 20373},\n",
       "   {'file_idx': 45, 'row_start': 0, 'row_end': 3169}]},\n",
       " {'batch_idx': 184,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 45, 'row_start': 3170, 'row_end': 8169}]},\n",
       " {'batch_idx': 185,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 45, 'row_start': 8170, 'row_end': 13169}]},\n",
       " {'batch_idx': 186,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 45, 'row_start': 13170, 'row_end': 18169}]},\n",
       " {'batch_idx': 187,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 45, 'row_start': 18170, 'row_end': 20373},\n",
       "   {'file_idx': 46, 'row_start': 0, 'row_end': 2795}]},\n",
       " {'batch_idx': 188,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 46, 'row_start': 2796, 'row_end': 7795}]},\n",
       " {'batch_idx': 189,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 46, 'row_start': 7796, 'row_end': 12795}]},\n",
       " {'batch_idx': 190,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 46, 'row_start': 12796, 'row_end': 17795}]},\n",
       " {'batch_idx': 191,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 46, 'row_start': 17796, 'row_end': 20373},\n",
       "   {'file_idx': 47, 'row_start': 0, 'row_end': 2421}]},\n",
       " {'batch_idx': 192,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 47, 'row_start': 2422, 'row_end': 7421}]},\n",
       " {'batch_idx': 193,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 47, 'row_start': 7422, 'row_end': 12421}]},\n",
       " {'batch_idx': 194,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 47, 'row_start': 12422, 'row_end': 17421}]},\n",
       " {'batch_idx': 195,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 47, 'row_start': 17422, 'row_end': 20373},\n",
       "   {'file_idx': 48, 'row_start': 0, 'row_end': 2047}]},\n",
       " {'batch_idx': 196,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 48, 'row_start': 2048, 'row_end': 7047}]},\n",
       " {'batch_idx': 197,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 48, 'row_start': 7048, 'row_end': 12047}]},\n",
       " {'batch_idx': 198,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 48, 'row_start': 12048, 'row_end': 17047}]},\n",
       " {'batch_idx': 199,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 48, 'row_start': 17048, 'row_end': 20373},\n",
       "   {'file_idx': 49, 'row_start': 0, 'row_end': 1673}]},\n",
       " {'batch_idx': 200,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 49, 'row_start': 1674, 'row_end': 6673}]},\n",
       " {'batch_idx': 201,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 49, 'row_start': 6674, 'row_end': 11673}]},\n",
       " {'batch_idx': 202,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 49, 'row_start': 11674, 'row_end': 16673}]},\n",
       " {'batch_idx': 203,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 49, 'row_start': 16674, 'row_end': 20373},\n",
       "   {'file_idx': 50, 'row_start': 0, 'row_end': 1299}]},\n",
       " {'batch_idx': 204,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 50, 'row_start': 1300, 'row_end': 6299}]},\n",
       " {'batch_idx': 205,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 50, 'row_start': 6300, 'row_end': 11299}]},\n",
       " {'batch_idx': 206,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 50, 'row_start': 11300, 'row_end': 16299}]},\n",
       " {'batch_idx': 207,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 50, 'row_start': 16300, 'row_end': 20373},\n",
       "   {'file_idx': 51, 'row_start': 0, 'row_end': 925}]},\n",
       " {'batch_idx': 208,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 51, 'row_start': 926, 'row_end': 5925}]},\n",
       " {'batch_idx': 209,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 51, 'row_start': 5926, 'row_end': 10925}]},\n",
       " {'batch_idx': 210,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 51, 'row_start': 10926, 'row_end': 15925}]},\n",
       " {'batch_idx': 211,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 51, 'row_start': 15926, 'row_end': 20373},\n",
       "   {'file_idx': 52, 'row_start': 0, 'row_end': 551}]},\n",
       " {'batch_idx': 212,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 52, 'row_start': 552, 'row_end': 5551}]},\n",
       " {'batch_idx': 213,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 52, 'row_start': 5552, 'row_end': 10551}]},\n",
       " {'batch_idx': 214,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 52, 'row_start': 10552, 'row_end': 15551}]},\n",
       " {'batch_idx': 215,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 52, 'row_start': 15552, 'row_end': 20373},\n",
       "   {'file_idx': 53, 'row_start': 0, 'row_end': 177}]},\n",
       " {'batch_idx': 216,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 53, 'row_start': 178, 'row_end': 5177}]},\n",
       " {'batch_idx': 217,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 53, 'row_start': 5178, 'row_end': 10177}]},\n",
       " {'batch_idx': 218,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 53, 'row_start': 10178, 'row_end': 15177}]},\n",
       " {'batch_idx': 219,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 53, 'row_start': 15178, 'row_end': 20177}]},\n",
       " {'batch_idx': 220,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 53, 'row_start': 20178, 'row_end': 20373},\n",
       "   {'file_idx': 54, 'row_start': 0, 'row_end': 4803}]},\n",
       " {'batch_idx': 221,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 54, 'row_start': 4804, 'row_end': 9803}]},\n",
       " {'batch_idx': 222,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 54, 'row_start': 9804, 'row_end': 14803}]},\n",
       " {'batch_idx': 223,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 54, 'row_start': 14804, 'row_end': 19803}]},\n",
       " {'batch_idx': 224,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 54, 'row_start': 19804, 'row_end': 20373},\n",
       "   {'file_idx': 55, 'row_start': 0, 'row_end': 4429}]},\n",
       " {'batch_idx': 225,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 55, 'row_start': 4430, 'row_end': 9429}]},\n",
       " {'batch_idx': 226,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 55, 'row_start': 9430, 'row_end': 14429}]},\n",
       " {'batch_idx': 227,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 55, 'row_start': 14430, 'row_end': 19429}]},\n",
       " {'batch_idx': 228,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 55, 'row_start': 19430, 'row_end': 20373},\n",
       "   {'file_idx': 56, 'row_start': 0, 'row_end': 4055}]},\n",
       " {'batch_idx': 229,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 56, 'row_start': 4056, 'row_end': 9055}]},\n",
       " {'batch_idx': 230,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 56, 'row_start': 9056, 'row_end': 14055}]},\n",
       " {'batch_idx': 231,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 56, 'row_start': 14056, 'row_end': 19055}]},\n",
       " {'batch_idx': 232,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 56, 'row_start': 19056, 'row_end': 20373},\n",
       "   {'file_idx': 57, 'row_start': 0, 'row_end': 3681}]},\n",
       " {'batch_idx': 233,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 57, 'row_start': 3682, 'row_end': 8681}]},\n",
       " {'batch_idx': 234,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 57, 'row_start': 8682, 'row_end': 13681}]},\n",
       " {'batch_idx': 235,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 57, 'row_start': 13682, 'row_end': 18681}]},\n",
       " {'batch_idx': 236,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 57, 'row_start': 18682, 'row_end': 20373},\n",
       "   {'file_idx': 58, 'row_start': 0, 'row_end': 3307}]},\n",
       " {'batch_idx': 237,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 58, 'row_start': 3308, 'row_end': 8307}]},\n",
       " {'batch_idx': 238,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 58, 'row_start': 8308, 'row_end': 13307}]},\n",
       " {'batch_idx': 239,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 58, 'row_start': 13308, 'row_end': 18307}]},\n",
       " {'batch_idx': 240,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 58, 'row_start': 18308, 'row_end': 20373},\n",
       "   {'file_idx': 59, 'row_start': 0, 'row_end': 2933}]},\n",
       " {'batch_idx': 241,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 59, 'row_start': 2934, 'row_end': 7933}]},\n",
       " {'batch_idx': 242,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 59, 'row_start': 7934, 'row_end': 12933}]},\n",
       " {'batch_idx': 243,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 59, 'row_start': 12934, 'row_end': 17933}]},\n",
       " {'batch_idx': 244,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 59, 'row_start': 17934, 'row_end': 20373},\n",
       "   {'file_idx': 60, 'row_start': 0, 'row_end': 2559}]},\n",
       " {'batch_idx': 245,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 60, 'row_start': 2560, 'row_end': 7559}]},\n",
       " {'batch_idx': 246,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 60, 'row_start': 7560, 'row_end': 12559}]},\n",
       " {'batch_idx': 247,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 60, 'row_start': 12560, 'row_end': 17559}]},\n",
       " {'batch_idx': 248,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 60, 'row_start': 17560, 'row_end': 20373},\n",
       "   {'file_idx': 61, 'row_start': 0, 'row_end': 2185}]},\n",
       " {'batch_idx': 249,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 61, 'row_start': 2186, 'row_end': 7185}]},\n",
       " {'batch_idx': 250,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 61, 'row_start': 7186, 'row_end': 12185}]},\n",
       " {'batch_idx': 251,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 61, 'row_start': 12186, 'row_end': 17185}]},\n",
       " {'batch_idx': 252,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 61, 'row_start': 17186, 'row_end': 20373},\n",
       "   {'file_idx': 62, 'row_start': 0, 'row_end': 1811}]},\n",
       " {'batch_idx': 253,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 62, 'row_start': 1812, 'row_end': 6811}]},\n",
       " {'batch_idx': 254,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 62, 'row_start': 6812, 'row_end': 11811}]},\n",
       " {'batch_idx': 255,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 62, 'row_start': 11812, 'row_end': 16811}]},\n",
       " {'batch_idx': 256,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 62, 'row_start': 16812, 'row_end': 20373},\n",
       "   {'file_idx': 63, 'row_start': 0, 'row_end': 1437}]},\n",
       " {'batch_idx': 257,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 63, 'row_start': 1438, 'row_end': 6437}]},\n",
       " {'batch_idx': 258,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 63, 'row_start': 6438, 'row_end': 11437}]},\n",
       " {'batch_idx': 259,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 63, 'row_start': 11438, 'row_end': 16437}]},\n",
       " {'batch_idx': 260,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 63, 'row_start': 16438, 'row_end': 20373},\n",
       "   {'file_idx': 64, 'row_start': 0, 'row_end': 1063}]},\n",
       " {'batch_idx': 261,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 64, 'row_start': 1064, 'row_end': 6063}]},\n",
       " {'batch_idx': 262,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 64, 'row_start': 6064, 'row_end': 11063}]},\n",
       " {'batch_idx': 263,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 64, 'row_start': 11064, 'row_end': 16063}]},\n",
       " {'batch_idx': 264,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 64, 'row_start': 16064, 'row_end': 20373},\n",
       "   {'file_idx': 65, 'row_start': 0, 'row_end': 689}]},\n",
       " {'batch_idx': 265,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 65, 'row_start': 690, 'row_end': 5689}]},\n",
       " {'batch_idx': 266,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 65, 'row_start': 5690, 'row_end': 10689}]},\n",
       " {'batch_idx': 267,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 65, 'row_start': 10690, 'row_end': 15689}]},\n",
       " {'batch_idx': 268,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 65, 'row_start': 15690, 'row_end': 20373},\n",
       "   {'file_idx': 66, 'row_start': 0, 'row_end': 315}]},\n",
       " {'batch_idx': 269,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 66, 'row_start': 316, 'row_end': 5315}]},\n",
       " {'batch_idx': 270,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 66, 'row_start': 5316, 'row_end': 10315}]},\n",
       " {'batch_idx': 271,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 66, 'row_start': 10316, 'row_end': 15315}]},\n",
       " {'batch_idx': 272,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 66, 'row_start': 15316, 'row_end': 20315}]},\n",
       " {'batch_idx': 273,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 66, 'row_start': 20316, 'row_end': 20373},\n",
       "   {'file_idx': 67, 'row_start': 0, 'row_end': 4941}]},\n",
       " {'batch_idx': 274,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 67, 'row_start': 4942, 'row_end': 9941}]},\n",
       " {'batch_idx': 275,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 67, 'row_start': 9942, 'row_end': 14941}]},\n",
       " {'batch_idx': 276,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 67, 'row_start': 14942, 'row_end': 19941}]},\n",
       " {'batch_idx': 277,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 67, 'row_start': 19942, 'row_end': 20373},\n",
       "   {'file_idx': 68, 'row_start': 0, 'row_end': 4567}]},\n",
       " {'batch_idx': 278,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 68, 'row_start': 4568, 'row_end': 9567}]},\n",
       " {'batch_idx': 279,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 68, 'row_start': 9568, 'row_end': 14567}]},\n",
       " {'batch_idx': 280,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 68, 'row_start': 14568, 'row_end': 19567}]},\n",
       " {'batch_idx': 281,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 68, 'row_start': 19568, 'row_end': 20373},\n",
       "   {'file_idx': 69, 'row_start': 0, 'row_end': 4193}]},\n",
       " {'batch_idx': 282,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 69, 'row_start': 4194, 'row_end': 9193}]},\n",
       " {'batch_idx': 283,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 69, 'row_start': 9194, 'row_end': 14193}]},\n",
       " {'batch_idx': 284,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 69, 'row_start': 14194, 'row_end': 19193}]},\n",
       " {'batch_idx': 285,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 69, 'row_start': 19194, 'row_end': 20373},\n",
       "   {'file_idx': 70, 'row_start': 0, 'row_end': 3819}]},\n",
       " {'batch_idx': 286,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 70, 'row_start': 3820, 'row_end': 8819}]},\n",
       " {'batch_idx': 287,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 70, 'row_start': 8820, 'row_end': 13819}]},\n",
       " {'batch_idx': 288,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 70, 'row_start': 13820, 'row_end': 18819}]},\n",
       " {'batch_idx': 289,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 70, 'row_start': 18820, 'row_end': 20373},\n",
       "   {'file_idx': 71, 'row_start': 0, 'row_end': 3445}]},\n",
       " {'batch_idx': 290,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 71, 'row_start': 3446, 'row_end': 8445}]},\n",
       " {'batch_idx': 291,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 71, 'row_start': 8446, 'row_end': 13445}]},\n",
       " {'batch_idx': 292,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 71, 'row_start': 13446, 'row_end': 18445}]},\n",
       " {'batch_idx': 293,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 71, 'row_start': 18446, 'row_end': 20373},\n",
       "   {'file_idx': 72, 'row_start': 0, 'row_end': 3071}]},\n",
       " {'batch_idx': 294,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 72, 'row_start': 3072, 'row_end': 8071}]},\n",
       " {'batch_idx': 295,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 72, 'row_start': 8072, 'row_end': 13071}]},\n",
       " {'batch_idx': 296,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 72, 'row_start': 13072, 'row_end': 18071}]},\n",
       " {'batch_idx': 297,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 72, 'row_start': 18072, 'row_end': 20373},\n",
       "   {'file_idx': 73, 'row_start': 0, 'row_end': 2697}]},\n",
       " {'batch_idx': 298,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 73, 'row_start': 2698, 'row_end': 7697}]},\n",
       " {'batch_idx': 299,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 73, 'row_start': 7698, 'row_end': 12697}]},\n",
       " {'batch_idx': 300,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 73, 'row_start': 12698, 'row_end': 17697}]},\n",
       " {'batch_idx': 301,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 73, 'row_start': 17698, 'row_end': 20373},\n",
       "   {'file_idx': 74, 'row_start': 0, 'row_end': 2323}]},\n",
       " {'batch_idx': 302,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 74, 'row_start': 2324, 'row_end': 7323}]},\n",
       " {'batch_idx': 303,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 5000,\n",
       "  'segments': [{'file_idx': 74, 'row_start': 7324, 'row_end': 12323}]},\n",
       " {'batch_idx': 304,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 4025,\n",
       "  'segments': [{'file_idx': 74, 'row_start': 12324, 'row_end': 16348}]},\n",
       " {'batch_idx': 305,\n",
       "  'target_batch_size': 5000,\n",
       "  'actual_batch_size': 4025,\n",
       "  'segments': [{'file_idx': 74, 'row_start': 16349, 'row_end': 20373}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.batch_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "4025\n",
      "4025\n"
     ]
    }
   ],
   "source": [
    "for bm in training_generator.batch_metadata:\n",
    "    print(bm['actual_batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cef1b-61db-489f-83bb-039a46861094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 22:49:04.064543: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 2)]       0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         33        \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2029 (7.93 KB)\n",
      "Trainable params: 2029 (7.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CreateModel((13,21,2),n_filters=5,pool_size=3)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=custom_loss\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60b630-5e1e-41cd-b9a0-7e9a06e9a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "os.makedirs(\"trained_models\", exist_ok=True)\n",
    "base_dir = f'./trained_models/model-{fingerprint}-checkpoints'\n",
    "os.makedirs(base_dir, exist_ok=True)  \n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc68b0-0d5a-4b14-bebc-0d8e6923e178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48fb7e34\n"
     ]
    }
   ],
   "source": [
    "print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97cbbf-a137-4a5c-9796-11de00abfa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "early_stopping_patience = 50\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        checkpoints = [f for f in os.listdir(base_dir) if f.startswith('weights')]\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints.sort()\n",
    "            for checkpoint in checkpoints[:-1]:\n",
    "                os.remove(os.path.join(base_dir, checkpoint))\n",
    "\n",
    "es = EarlyStopping(patience=early_stopping_patience, restore_best_weights=True)\n",
    "\n",
    "mcp = CustomModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(f'{base_dir}/training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 22:49:11.020594: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-06-09 22:49:11.660478: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-06-09 22:49:12.300412: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x5597663af670\n",
      "2025-06-09 22:49:14.847814: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7ea6d78170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-09 22:49:14.847886: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2025-06-09 22:49:15.040167: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749502155.233285 3606183 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - ETA: 0s - loss: 14565.7441\n",
      "Epoch 1: val_loss improved from inf to 2447.44678, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.01-t14565.74-v2447.45.hdf5\n",
      "306/306 [==============================] - 39s 96ms/step - loss: 14565.7441 - val_loss: 2447.4468\n",
      "Epoch 2/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10.5925\n",
      "Epoch 2: val_loss improved from 2447.44678 to -2276.42358, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.02-t-10.59-v-2276.42.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -10.5925 - val_loss: -2276.4236\n",
      "Epoch 3/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -3494.1912\n",
      "Epoch 3: val_loss improved from -2276.42358 to -3644.90308, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.03-t-3494.19-v-3644.90.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -3494.1912 - val_loss: -3644.9031\n",
      "Epoch 4/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -5685.8213\n",
      "Epoch 4: val_loss improved from -3644.90308 to -6670.18848, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.04-t-5685.82-v-6670.19.hdf5\n",
      "306/306 [==============================] - 30s 98ms/step - loss: -5685.8213 - val_loss: -6670.1885\n",
      "Epoch 5/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -6968.4370\n",
      "Epoch 5: val_loss improved from -6670.18848 to -7559.18066, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.05-t-6968.44-v-7559.18.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -6968.4370 - val_loss: -7559.1807\n",
      "Epoch 6/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8160.1514\n",
      "Epoch 6: val_loss improved from -7559.18066 to -8097.05957, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.06-t-8160.15-v-8097.06.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -8160.1514 - val_loss: -8097.0596\n",
      "Epoch 7/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -6515.2939\n",
      "Epoch 7: val_loss did not improve from -8097.05957\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -6515.2939 - val_loss: -7413.9839\n",
      "Epoch 8/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -7465.2788\n",
      "Epoch 8: val_loss did not improve from -8097.05957\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -7465.2788 - val_loss: -6895.8457\n",
      "Epoch 9/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -7404.8633\n",
      "Epoch 9: val_loss improved from -8097.05957 to -8139.77246, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.09-t-7404.86-v-8139.77.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -7404.8633 - val_loss: -8139.7725\n",
      "Epoch 10/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8104.1816\n",
      "Epoch 10: val_loss improved from -8139.77246 to -8205.09961, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.10-t-8104.18-v-8205.10.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -8104.1816 - val_loss: -8205.0996\n",
      "Epoch 11/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8685.9121\n",
      "Epoch 11: val_loss improved from -8205.09961 to -9217.47852, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.11-t-8685.91-v-9217.48.hdf5\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -8685.9121 - val_loss: -9217.4785\n",
      "Epoch 12/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -7262.9844\n",
      "Epoch 12: val_loss did not improve from -9217.47852\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -7262.9844 - val_loss: -8643.6709\n",
      "Epoch 13/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8536.1191\n",
      "Epoch 13: val_loss improved from -9217.47852 to -9476.15234, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.13-t-8536.12-v-9476.15.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -8536.1191 - val_loss: -9476.1523\n",
      "Epoch 14/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -9202.2510\n",
      "Epoch 14: val_loss did not improve from -9476.15234\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -9202.2510 - val_loss: -9460.9189\n",
      "Epoch 15/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8583.0254\n",
      "Epoch 15: val_loss improved from -9476.15234 to -9908.73242, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.15-t-8583.03-v-9908.73.hdf5\n",
      "306/306 [==============================] - 27s 90ms/step - loss: -8583.0254 - val_loss: -9908.7324\n",
      "Epoch 16/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -9318.7744\n",
      "Epoch 16: val_loss improved from -9908.73242 to -10136.53125, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.16-t-9318.77-v-10136.53.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -9318.7744 - val_loss: -10136.5312\n",
      "Epoch 17/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -9499.4609\n",
      "Epoch 17: val_loss improved from -10136.53125 to -10229.72656, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.17-t-9499.46-v-10229.73.hdf5\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -9499.4609 - val_loss: -10229.7266\n",
      "Epoch 18/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8546.7217\n",
      "Epoch 18: val_loss did not improve from -10229.72656\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -8546.7217 - val_loss: -9686.5674\n",
      "Epoch 19/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -8324.1064\n",
      "Epoch 19: val_loss did not improve from -10229.72656\n",
      "306/306 [==============================] - 27s 89ms/step - loss: -8324.1064 - val_loss: -9048.7461\n",
      "Epoch 20/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -9220.6885\n",
      "Epoch 20: val_loss did not improve from -10229.72656\n",
      "306/306 [==============================] - 30s 99ms/step - loss: -9220.6885 - val_loss: -8648.5820\n",
      "Epoch 21/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10152.2510\n",
      "Epoch 21: val_loss improved from -10229.72656 to -10771.57617, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.21-t-10152.25-v-10771.58.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -10152.2510 - val_loss: -10771.5762\n",
      "Epoch 22/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10637.2617\n",
      "Epoch 22: val_loss improved from -10771.57617 to -11259.73730, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.22-t-10637.26-v-11259.74.hdf5\n",
      "306/306 [==============================] - 27s 89ms/step - loss: -10637.2617 - val_loss: -11259.7373\n",
      "Epoch 23/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10842.9453\n",
      "Epoch 23: val_loss did not improve from -11259.73730\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -10842.9453 - val_loss: -10784.7031\n",
      "Epoch 24/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10435.6523\n",
      "Epoch 24: val_loss did not improve from -11259.73730\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -10435.6523 - val_loss: -11230.3193\n",
      "Epoch 25/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11309.5439\n",
      "Epoch 25: val_loss improved from -11259.73730 to -11819.12305, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.25-t-11309.54-v-11819.12.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -11309.5439 - val_loss: -11819.1230\n",
      "Epoch 26/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11292.6875\n",
      "Epoch 26: val_loss improved from -11819.12305 to -12195.09473, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.26-t-11292.69-v-12195.09.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -11292.6875 - val_loss: -12195.0947\n",
      "Epoch 27/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11286.7070\n",
      "Epoch 27: val_loss did not improve from -12195.09473\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -11286.7070 - val_loss: -11358.2344\n",
      "Epoch 28/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11281.3203\n",
      "Epoch 28: val_loss did not improve from -12195.09473\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -11281.3203 - val_loss: -11394.1963\n",
      "Epoch 29/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10390.1602\n",
      "Epoch 29: val_loss did not improve from -12195.09473\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -10390.1602 - val_loss: -11460.3779\n",
      "Epoch 30/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -10583.2246\n",
      "Epoch 30: val_loss did not improve from -12195.09473\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -10583.2246 - val_loss: -11427.9482\n",
      "Epoch 31/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11524.5137\n",
      "Epoch 31: val_loss did not improve from -12195.09473\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -11524.5137 - val_loss: -4256.5469\n",
      "Epoch 32/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11238.0771\n",
      "Epoch 32: val_loss improved from -12195.09473 to -12345.78711, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.32-t-11238.08-v-12345.79.hdf5\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -11238.0771 - val_loss: -12345.7871\n",
      "Epoch 33/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -11702.4521\n",
      "Epoch 33: val_loss improved from -12345.78711 to -12409.70801, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.33-t-11702.45-v-12409.71.hdf5\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -11702.4521 - val_loss: -12409.7080\n",
      "Epoch 34/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -12175.5498\n",
      "Epoch 34: val_loss did not improve from -12409.70801\n",
      "306/306 [==============================] - 27s 89ms/step - loss: -12175.5498 - val_loss: -12186.6855\n",
      "Epoch 35/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -12549.5977\n",
      "Epoch 35: val_loss improved from -12409.70801 to -13502.03613, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.35-t-12549.60-v-13502.04.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -12549.5977 - val_loss: -13502.0361\n",
      "Epoch 36/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -12807.7568\n",
      "Epoch 36: val_loss did not improve from -13502.03613\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -12807.7568 - val_loss: -12876.9570\n",
      "Epoch 37/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13115.6650\n",
      "Epoch 37: val_loss improved from -13502.03613 to -13671.99023, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.37-t-13115.67-v-13671.99.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -13115.6650 - val_loss: -13671.9902\n",
      "Epoch 38/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13525.7822\n",
      "Epoch 38: val_loss improved from -13671.99023 to -13802.63965, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.38-t-13525.78-v-13802.64.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -13525.7822 - val_loss: -13802.6396\n",
      "Epoch 39/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13512.5049\n",
      "Epoch 39: val_loss did not improve from -13802.63965\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -13512.5049 - val_loss: -12689.3398\n",
      "Epoch 40/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13825.7002\n",
      "Epoch 40: val_loss improved from -13802.63965 to -14052.42090, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.40-t-13825.70-v-14052.42.hdf5\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -13825.7002 - val_loss: -14052.4209\n",
      "Epoch 41/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14060.1104\n",
      "Epoch 41: val_loss improved from -14052.42090 to -14417.46680, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.41-t-14060.11-v-14417.47.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -14060.1104 - val_loss: -14417.4668\n",
      "Epoch 42/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13846.5723\n",
      "Epoch 42: val_loss did not improve from -14417.46680\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -13846.5723 - val_loss: -12614.4697\n",
      "Epoch 43/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14084.9482\n",
      "Epoch 43: val_loss improved from -14417.46680 to -14853.97461, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.43-t-14084.95-v-14853.97.hdf5\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -14084.9482 - val_loss: -14853.9746\n",
      "Epoch 44/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14667.5439\n",
      "Epoch 44: val_loss improved from -14853.97461 to -15427.73828, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.44-t-14667.54-v-15427.74.hdf5\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -14667.5439 - val_loss: -15427.7383\n",
      "Epoch 45/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15186.6074\n",
      "Epoch 45: val_loss did not improve from -15427.73828\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15186.6074 - val_loss: -14984.3467\n",
      "Epoch 46/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15066.8184\n",
      "Epoch 46: val_loss improved from -15427.73828 to -15479.54492, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.46-t-15066.82-v-15479.54.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -15066.8184 - val_loss: -15479.5449\n",
      "Epoch 47/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15322.6738\n",
      "Epoch 47: val_loss did not improve from -15479.54492\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -15322.6738 - val_loss: -13656.0537\n",
      "Epoch 48/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15528.4053\n",
      "Epoch 48: val_loss improved from -15479.54492 to -16070.95605, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.48-t-15528.41-v-16070.96.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15528.4053 - val_loss: -16070.9561\n",
      "Epoch 49/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15534.8076\n",
      "Epoch 49: val_loss did not improve from -16070.95605\n",
      "306/306 [==============================] - 31s 100ms/step - loss: -15534.8076 - val_loss: -16018.7324\n",
      "Epoch 50/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15492.4150\n",
      "Epoch 50: val_loss did not improve from -16070.95605\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -15492.4150 - val_loss: -15631.0205\n",
      "Epoch 51/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -13817.2578\n",
      "Epoch 51: val_loss did not improve from -16070.95605\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -13817.2578 - val_loss: -14347.2197\n",
      "Epoch 52/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14979.0498\n",
      "Epoch 52: val_loss did not improve from -16070.95605\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -14979.0498 - val_loss: -12803.6885\n",
      "Epoch 53/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15508.6709\n",
      "Epoch 53: val_loss improved from -16070.95605 to -16119.85449, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.53-t-15508.67-v-16119.85.hdf5\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -15508.6709 - val_loss: -16119.8545\n",
      "Epoch 54/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15077.0918\n",
      "Epoch 54: val_loss improved from -16119.85449 to -16343.83496, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.54-t-15077.09-v-16343.83.hdf5\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -15077.0918 - val_loss: -16343.8350\n",
      "Epoch 55/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15750.7559\n",
      "Epoch 55: val_loss did not improve from -16343.83496\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -15750.7559 - val_loss: -16155.1299\n",
      "Epoch 56/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15705.2686\n",
      "Epoch 56: val_loss did not improve from -16343.83496\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -15705.2686 - val_loss: -15222.8428\n",
      "Epoch 57/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15719.6934\n",
      "Epoch 57: val_loss did not improve from -16343.83496\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15719.6934 - val_loss: -16216.4922\n",
      "Epoch 58/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14285.3154\n",
      "Epoch 58: val_loss did not improve from -16343.83496\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -14285.3154 - val_loss: -14998.7607\n",
      "Epoch 59/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14972.9639\n",
      "Epoch 59: val_loss improved from -16343.83496 to -16352.94922, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.59-t-14972.96-v-16352.95.hdf5\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -14972.9639 - val_loss: -16352.9492\n",
      "Epoch 60/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15347.3330\n",
      "Epoch 60: val_loss did not improve from -16352.94922\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -15347.3330 - val_loss: -16029.7334\n",
      "Epoch 61/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -14809.6641\n",
      "Epoch 61: val_loss did not improve from -16352.94922\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -14809.6641 - val_loss: -15977.0049\n",
      "Epoch 62/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15664.9004\n",
      "Epoch 62: val_loss improved from -16352.94922 to -16857.05664, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.62-t-15664.90-v-16857.06.hdf5\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -15664.9004 - val_loss: -16857.0566\n",
      "Epoch 63/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15716.4365\n",
      "Epoch 63: val_loss did not improve from -16857.05664\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15716.4365 - val_loss: -16613.1367\n",
      "Epoch 64/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16244.3428\n",
      "Epoch 64: val_loss did not improve from -16857.05664\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -16244.3428 - val_loss: -9635.7822\n",
      "Epoch 65/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16401.8867\n",
      "Epoch 65: val_loss did not improve from -16857.05664\n",
      "306/306 [==============================] - 27s 90ms/step - loss: -16401.8867 - val_loss: -15548.9854\n",
      "Epoch 66/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16006.0557\n",
      "Epoch 66: val_loss improved from -16857.05664 to -17234.11133, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.66-t-16006.06-v-17234.11.hdf5\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -16006.0557 - val_loss: -17234.1113\n",
      "Epoch 67/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16230.8350\n",
      "Epoch 67: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -16230.8350 - val_loss: -16119.2969\n",
      "Epoch 68/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15241.6289\n",
      "Epoch 68: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -15241.6289 - val_loss: -16007.9844\n",
      "Epoch 69/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15402.5078\n",
      "Epoch 69: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -15402.5078 - val_loss: -16384.6641\n",
      "Epoch 70/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15535.7080\n",
      "Epoch 70: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 30s 99ms/step - loss: -15535.7080 - val_loss: -13249.0391\n",
      "Epoch 71/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15248.9141\n",
      "Epoch 71: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -15248.9141 - val_loss: -16807.4902\n",
      "Epoch 72/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15610.0420\n",
      "Epoch 72: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -15610.0420 - val_loss: -16746.6738\n",
      "Epoch 73/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15889.1172\n",
      "Epoch 73: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -15889.1172 - val_loss: -16932.8281\n",
      "Epoch 74/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15630.4062\n",
      "Epoch 74: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -15630.4062 - val_loss: -15177.8008\n",
      "Epoch 75/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15435.3340\n",
      "Epoch 75: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15435.3340 - val_loss: -14138.3076\n",
      "Epoch 76/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15314.7158\n",
      "Epoch 76: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -15314.7158 - val_loss: -14778.7412\n",
      "Epoch 77/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15663.4121\n",
      "Epoch 77: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -15663.4121 - val_loss: -16746.3730\n",
      "Epoch 78/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15915.1055\n",
      "Epoch 78: val_loss did not improve from -17234.11133\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -15915.1055 - val_loss: -13882.7822\n",
      "Epoch 79/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16136.2754\n",
      "Epoch 79: val_loss improved from -17234.11133 to -17387.96289, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.79-t-16136.28-v-17387.96.hdf5\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -16136.2754 - val_loss: -17387.9629\n",
      "Epoch 80/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -15954.6475\n",
      "Epoch 80: val_loss did not improve from -17387.96289\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -15954.6475 - val_loss: -16789.2441\n",
      "Epoch 81/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16218.3789\n",
      "Epoch 81: val_loss improved from -17387.96289 to -17567.37891, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.81-t-16218.38-v-17567.38.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -16218.3789 - val_loss: -17567.3789\n",
      "Epoch 82/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16611.3535\n",
      "Epoch 82: val_loss improved from -17567.37891 to -17927.48438, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.82-t-16611.35-v-17927.48.hdf5\n",
      "306/306 [==============================] - 33s 108ms/step - loss: -16611.3535 - val_loss: -17927.4844\n",
      "Epoch 83/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16229.5039\n",
      "Epoch 83: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -16229.5039 - val_loss: -17531.2812\n",
      "Epoch 84/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16531.8418\n",
      "Epoch 84: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -16531.8418 - val_loss: -16935.5078\n",
      "Epoch 85/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16624.4668\n",
      "Epoch 85: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 27s 90ms/step - loss: -16624.4668 - val_loss: -17592.2051\n",
      "Epoch 86/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16858.0195\n",
      "Epoch 86: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -16858.0195 - val_loss: -17503.5898\n",
      "Epoch 87/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16831.3398\n",
      "Epoch 87: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -16831.3398 - val_loss: -15509.3350\n",
      "Epoch 88/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16969.6191\n",
      "Epoch 88: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 29s 95ms/step - loss: -16969.6191 - val_loss: -15735.3008\n",
      "Epoch 89/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -16924.5371\n",
      "Epoch 89: val_loss did not improve from -17927.48438\n",
      "306/306 [==============================] - 29s 96ms/step - loss: -16924.5371 - val_loss: -17266.7363\n",
      "Epoch 90/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17470.2754\n",
      "Epoch 90: val_loss improved from -17927.48438 to -18179.04883, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.90-t-17470.28-v-18179.05.hdf5\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -17470.2754 - val_loss: -18179.0488\n",
      "Epoch 91/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17923.5703\n",
      "Epoch 91: val_loss did not improve from -18179.04883\n",
      "306/306 [==============================] - 32s 105ms/step - loss: -17923.5703 - val_loss: -17974.8320\n",
      "Epoch 92/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17964.4512\n",
      "Epoch 92: val_loss did not improve from -18179.04883\n",
      "306/306 [==============================] - 31s 101ms/step - loss: -17964.4512 - val_loss: -17203.3984\n",
      "Epoch 93/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17620.5254\n",
      "Epoch 93: val_loss did not improve from -18179.04883\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -17620.5254 - val_loss: -18059.8496\n",
      "Epoch 94/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17605.6133\n",
      "Epoch 94: val_loss did not improve from -18179.04883\n",
      "306/306 [==============================] - 29s 93ms/step - loss: -17605.6133 - val_loss: -17300.8984\n",
      "Epoch 95/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -17780.7891\n",
      "Epoch 95: val_loss did not improve from -18179.04883\n",
      "306/306 [==============================] - 31s 101ms/step - loss: -17780.7891 - val_loss: -16068.2832\n",
      "Epoch 96/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -18117.3145\n",
      "Epoch 96: val_loss improved from -18179.04883 to -18253.23828, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.96-t-18117.31-v-18253.24.hdf5\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -18117.3145 - val_loss: -18253.2383\n",
      "Epoch 97/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -18333.8203\n",
      "Epoch 97: val_loss improved from -18253.23828 to -19403.96680, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.97-t-18333.82-v-19403.97.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -18333.8203 - val_loss: -19403.9668\n",
      "Epoch 98/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -18607.7812\n",
      "Epoch 98: val_loss improved from -19403.96680 to -19578.54492, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.98-t-18607.78-v-19578.54.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -18607.7812 - val_loss: -19578.5449\n",
      "Epoch 99/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19223.6543\n",
      "Epoch 99: val_loss improved from -19578.54492 to -19890.74609, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.99-t-19223.65-v-19890.75.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -19223.6543 - val_loss: -19890.7461\n",
      "Epoch 100/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19392.8398\n",
      "Epoch 100: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -19392.8398 - val_loss: -19575.5156\n",
      "Epoch 101/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19187.8613\n",
      "Epoch 101: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -19187.8613 - val_loss: -19093.6074\n",
      "Epoch 102/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19112.0684\n",
      "Epoch 102: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 30s 98ms/step - loss: -19112.0684 - val_loss: -19004.8457\n",
      "Epoch 103/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19259.3789\n",
      "Epoch 103: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -19259.3789 - val_loss: -19597.3223\n",
      "Epoch 104/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19569.2812\n",
      "Epoch 104: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 27s 88ms/step - loss: -19569.2812 - val_loss: -19581.7148\n",
      "Epoch 105/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19578.6914\n",
      "Epoch 105: val_loss did not improve from -19890.74609\n",
      "306/306 [==============================] - 27s 88ms/step - loss: -19578.6914 - val_loss: -19890.6426\n",
      "Epoch 106/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19562.5117\n",
      "Epoch 106: val_loss improved from -19890.74609 to -20487.32031, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.106-t-19562.51-v-20487.32.hdf5\n",
      "306/306 [==============================] - 28s 92ms/step - loss: -19562.5117 - val_loss: -20487.3203\n",
      "Epoch 107/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19642.3164\n",
      "Epoch 107: val_loss did not improve from -20487.32031\n",
      "306/306 [==============================] - 27s 87ms/step - loss: -19642.3164 - val_loss: -20011.3008\n",
      "Epoch 108/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19700.3477\n",
      "Epoch 108: val_loss did not improve from -20487.32031\n",
      "306/306 [==============================] - 27s 87ms/step - loss: -19700.3477 - val_loss: -19722.3672\n",
      "Epoch 109/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19723.7285\n",
      "Epoch 109: val_loss did not improve from -20487.32031\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -19723.7285 - val_loss: -19526.2871\n",
      "Epoch 110/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19446.9648\n",
      "Epoch 110: val_loss did not improve from -20487.32031\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -19446.9648 - val_loss: -17528.4863\n",
      "Epoch 111/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -20062.3574\n",
      "Epoch 111: val_loss did not improve from -20487.32031\n",
      "306/306 [==============================] - 30s 96ms/step - loss: -20062.3574 - val_loss: -20230.4082\n",
      "Epoch 112/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -20101.2109\n",
      "Epoch 112: val_loss improved from -20487.32031 to -20539.14258, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.112-t-20101.21-v-20539.14.hdf5\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -20101.2109 - val_loss: -20539.1426\n",
      "Epoch 113/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -20121.2207\n",
      "Epoch 113: val_loss improved from -20539.14258 to -20801.39844, saving model to ./trained_models/model-48fb7e34-checkpoints/weights.113-t-20121.22-v-20801.40.hdf5\n",
      "306/306 [==============================] - 29s 94ms/step - loss: -20121.2207 - val_loss: -20801.3984\n",
      "Epoch 114/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19183.8301\n",
      "Epoch 114: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 31s 102ms/step - loss: -19183.8301 - val_loss: -14418.2764\n",
      "Epoch 115/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19213.2051\n",
      "Epoch 115: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 27s 87ms/step - loss: -19213.2051 - val_loss: -20259.7402\n",
      "Epoch 116/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19037.5020\n",
      "Epoch 116: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 28s 93ms/step - loss: -19037.5020 - val_loss: -19989.4512\n",
      "Epoch 117/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -20092.3027\n",
      "Epoch 117: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -20092.3027 - val_loss: -20678.0508\n",
      "Epoch 118/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -20032.6172\n",
      "Epoch 118: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 27s 88ms/step - loss: -20032.6172 - val_loss: -20702.4707\n",
      "Epoch 119/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19301.9688\n",
      "Epoch 119: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 28s 90ms/step - loss: -19301.9688 - val_loss: -18399.0898\n",
      "Epoch 120/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19443.0957\n",
      "Epoch 120: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 28s 91ms/step - loss: -19443.0957 - val_loss: -19050.0020\n",
      "Epoch 121/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19479.5859\n",
      "Epoch 121: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 30s 97ms/step - loss: -19479.5859 - val_loss: -18249.6895\n",
      "Epoch 122/1000\n",
      "306/306 [==============================] - ETA: 0s - loss: -19776.1953\n",
      "Epoch 122: val_loss did not improve from -20801.39844\n",
      "306/306 [==============================] - 31s 102ms/step - loss: -19776.1953 - val_loss: -19257.1309\n",
      "Epoch 123/1000\n",
      "117/306 [==========>...................] - ETA: 13s - loss: -19861.2637"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:230\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    220\u001b[0m current_func_context \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_function_context(\n\u001b[1;32m    221\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mscope_type\n\u001b[1;32m    222\u001b[0m )\n\u001b[1;32m    224\u001b[0m capture_types \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_canonicalized_monomorphic_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolymorphic_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39mlookup(\n\u001b[1;32m    240\u001b[0m       lookup_func_type, current_func_context\n\u001b[1;32m    241\u001b[0m   )\n",
      "File \u001b[0;32m/depot/cms/kernels/python3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:362\u001b[0m, in \u001b[0;36mmake_canonicalized_monomorphic_type\u001b[0;34m(args, kwargs, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    355\u001b[0m     function_type \u001b[38;5;241m=\u001b[39m function_type_lib\u001b[38;5;241m.\u001b[39madd_type_constraints(\n\u001b[1;32m    356\u001b[0m         function_type, input_signature, default_values\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function_type, default_values\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_canonicalized_monomorphic_type\u001b[39m(\n\u001b[1;32m    363\u001b[0m     args: Any,\n\u001b[1;32m    364\u001b[0m     kwargs: Any,\n\u001b[1;32m    365\u001b[0m     capture_types: Any,\n\u001b[1;32m    366\u001b[0m     polymorphic_type,\n\u001b[1;32m    367\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[function_type_lib\u001b[38;5;241m.\u001b[39mFunctionType, trace_type\u001b[38;5;241m.\u001b[39mInternalTracingContext]:\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates function type given the function arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    370\u001b[0m       function_type_lib\u001b[38;5;241m.\u001b[39msanitize_arg_name(name): value\n\u001b[1;32m    371\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    372\u001b[0m   }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        x=training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[es, mcp, csv_logger],\n",
    "        epochs=1000,\n",
    "        shuffle=False,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e2706-3e27-4ece-9ebd-be135f6bbcb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://cms.geddes.rcac.purdue.edu/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'https://cms.geddes.rcac.purdue.edu/'. Verify the server is running and reachable. (Invalid response: 504 Gateway Time-out).)."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Epoch 1/1000\n",
    "305/305 [==============================] - ETA: 0s - loss: 27173.7227\n",
    "Epoch 1: val_loss improved from inf to 3957.69629, saving model to ./trained_models/model-e0ef8b33-checkpoints/weights.01-t27173.72-v3957.70.hdf5\n",
    "305/305 [==============================] - 34s 102ms/step - loss: 27173.7227 - val_loss: 3957.6963\n",
    "Epoch 2/1000\n",
    "305/305 [==============================] - ETA: 0s - loss: 2077.7952\n",
    "Epoch 2: val_loss improved from 3957.69629 to -473.36844, saving model to ./trained_models/model-e0ef8b33-checkpoints/weights.02-t2077.80-v-473.37.hdf5\n",
    "305/305 [==============================] - 30s 97ms/step - loss: 2077.7952 - val_loss: -473.3684\n",
    "Epoch 3/1000\n",
    "305/305 [==============================] - ETA: 0s - loss: -935.6221\n",
    "Epoch 3: val_loss improved from -473.36844 to -1284.97668, saving model to ./trained_models/model-e0ef8b33-checkpoints/weights.03-t-935.62-v-1284.98.hdf5\n",
    "305/305 [==============================] - 61s 199ms/step - loss: -935.6221 - val_loss: -1284.9767\n",
    "Epoch 4/1000\n",
    "305/305 [==============================] - ETA: 0s - loss: -484.1406\n",
    "Epoch 4: val_loss improved from -1284.97668 to -1554.20630, saving model to ./trained_models/model-e0ef8b33-checkpoints/weights.04-t-484.14-v-1554.21.hdf5\n",
    "305/305 [==============================] - 36s 116ms/step - loss: -484.1406 - val_loss: -1554.2063\n",
    "Epoch 5/1000\n",
    "305/305 [==============================] - ETA: 0s - loss: -3135.4961\n",
    "Epoch 5: val_loss improved from -1554.20630 to -2936.62402, saving model to ./trained_models/model-e0ef8b33-checkpoints/weights.05-t-3135.50-v-2936.62.hdf5\n",
    "305/305 [==============================] - 40s 130ms/step - loss: -3135.4961 - val_loss: -2936.6240\n",
    "Epoch 6/1000\n",
    " 38/305 [==>...........................] - ETA: 19s - loss: -3885.3333\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866bd46",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://cms.geddes.rcac.purdue.edu/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'https://cms.geddes.rcac.purdue.edu/'. Verify the server is running and reachable. (Invalid response: 504 Gateway Time-out).)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb1ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a6d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
