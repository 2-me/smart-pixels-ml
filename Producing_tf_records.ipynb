{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd8a454-afa9-40d3-a9a4-db3dee99c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 20:30:53.601443: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 20:30:53.601523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 20:30:53.603280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 20:30:53.612514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 20:30:57.165034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9\n",
    "\n",
    "import OptimizedDataGenerator as DG\n",
    "from loss import *\n",
    "from models import *\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d602b-6c11-4786-b0d8-351084bfc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf50778-7cf3-4af2-90cd-1535a60289d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 104\n",
    "val_file_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88fc0-6c3b-4149-ae9f-743bd8996b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2839c3ea-712e-4391-93ef-62bae8b25abd",
   "metadata": {},
   "source": [
    "## Make the tf records\n",
    "\n",
    "The following happened when training with dataset18-3D\n",
    "\n",
    "When using the OptimizedDataGenerator to create tfrecord for training, the tfrecord would be \"broken\" after the first use (training with it will only lead to a plateau of loss at around 10k). Recreateing the tfrecord and using it will solve this issue, where the model converges as expected. This bug can be avoided by using optimized DG to create tfrecord before each new training (instead of using used tfrecord). I discussed with Arghya on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05867e-7e4b-4014-b1a5-54026bdf4475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e23b782-1eda-4c9d-b37b-0ec501dc7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_path = \"/depot/cms/users/kuang14/Smart_Pixel/dataset18-3D/recon3D/\"\n",
    "labels_directory_path = \"/depot/cms/users/kuang14/Smart_Pixel/dataset18-3D/labels/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d4ff0-5a2f-4268-9e4e-f532298f11f7",
   "metadata": {},
   "source": [
    "Create a new tfrecord can avoid the problem of not converging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5534fd39-1d5b-4db8-b74d-6bf467e33a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords_dir_train = \"/depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_train\"\n",
    "tfrecords_dir_validation = \"/depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab084b1-d48e-4af5-adda-ca78267495d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bb61f5-a97a-418b-a2d9-16098fb81134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_train3 does not exist and cannot be removed.\n",
      "Directory /depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_val3 does not exist and cannot be removed.\n"
     ]
    }
   ],
   "source": [
    "utils.safe_remove_directory(tfrecords_dir_train)\n",
    "utils.safe_remove_directory(tfrecords_dir_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7762be-6fac-4474-bbe6-9d532abbc6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_val3 does not exist and cannot be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 6/6 [00:03<00:00,  1.98it/s]\n",
      "Saving batches as TFRecords: 100%|██████████| 59/59 [00:07<00:00,  7.50it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = DG.OptimizedDataGenerator(\n",
    "    data_directory_path = data_directory_path,\n",
    "    labels_directory_path = labels_directory_path,\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False, \n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,13,21), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, \n",
    "    files_from_end=True,\n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_validation,\n",
    "    use_time_stamps = [0, 19], #-1\n",
    "    max_workers = 2 # Don't make this too large (will use up all RAM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21749667-77a1-4774-8efa-795f19288ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /depot/cms/users/kuang14/Smart_Pixel/tf_records/tfrecords_2t_dataset18_bs5000_val3 is removed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 104/104 [00:48<00:00,  2.13it/s]\n",
      "Saving batches as TFRecords: 100%|██████████| 1028/1028 [02:13<00:00,  7.71it/s]\n",
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "train_generator = DG.OptimizedDataGenerator(\n",
    "    data_directory_path = data_directory_path,\n",
    "    labels_directory_path = labels_directory_path,\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False, \n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    input_shape = (2,13,21), # (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, \n",
    "    files_from_end=True,\n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_validation,\n",
    "    use_time_stamps = [0, 19], #-1\n",
    "    max_workers = 2 # Don't make this too large (will use up all RAM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560fd7f1-5997-484b-a149-6151c38a04ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
